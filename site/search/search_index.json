{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Tile-level Histopathology image Understanding benchmark","text":"<p>We introduce THUNDER, a comprehensive benchmark designed to rigorously compare foundation models across various downstream tasks in computational pathology. THUNDER enables the evaluation and analysis of feature representations, robustness, and uncertainty quantification of these models across different datasets. Our benchmark encompasses a diverse collection of well-established datasets, covering multiple cancer types, image magnifications, and varying image and sample sizes. We propose an extensive set of tasks aimed at thoroughly assessing the capabilities and limitations of foundation models in digital pathology.</p>"},{"location":"#overview","title":"Overview","text":"<p>We propose a benchmark to compare and study foundation models across three axes: (i) downstream task performance, (ii) feature space comparisons, and (iii) uncertainty and robustness. Our current version integrates 23 foundation models, vision-only, vision-language, trained on pathology or natural images, on 16 datasets covering different magnifications and organs. THUNDER also supports the use of new user-defined models for direct comparisons.</p> <p></p>"},{"location":"#usage","title":"Usage","text":"<p>An API and command line interface (CLI) are provided to allow users to download datasets, models, and run benchmarks. The API is designed to be user-friendly and allows for easy integration into existing workflows. The CLI provides a convenient way to access the same functionality from the command line.</p> <p>Important</p> <p>Downloading supported foundation models: you will have to visit the Huggingface URL of supported models you wish to use in order to accept usage conditions.</p>"},{"location":"#api-usage","title":"API Usage","text":"<p>When using the API you can run the following code to download datasets, models and run a benchmark:</p> <pre><code>from thunder import benchmark\n\nbenchmark(\"phikon\", \"break_his\", \"knn\")\n</code></pre>"},{"location":"#cli-usage","title":"CLI Usage","text":"<p>When using the CLI you can run the following command to see all available options,</p> <pre><code>thunder --help\n</code></pre> <p>In order to reproduce the above example you can run the following command:</p> <pre><code>thunder benchmark phikon break_his  knn\n</code></pre>"},{"location":"#installing-thunder","title":"Installing thunder","text":"<p>Code tested with Python 3.10. To replicate, you can create the following conda environment and activate it, <pre><code>conda create -n thunder_env python=3.10\nconda activate thunder_env\n</code></pre></p> <p>To install <code>thunder</code> run the following command:</p> <pre><code>pip install -e . # install the package in editable mode\npip install . # install the package\n</code></pre>"},{"location":"#available-datasets","title":"Available datasets","text":"Name Short name Labels Nb. classes Organ(s) Image size Magnification Nb. images BACH bach Classif. 4 Breast 1,536x2,048 20x 408 BRACS bracs Classif. 7 Breast Variable 40x 4,539 BreakHis break-h Classif. 8 Breast 700x460 40x 1,995 Camelyon17 WILDS wilds Classif. 2 Breast 96x96 10x 302,436 Patch Camelyon pcam Classif. 2 Breast 96x96 10x 327,680 CCRCC ccrcc Classif. 3 Renal 300x300 40x 52,713 CRC-100k crc Classif. 9 CRC 224x224 20x 107,180 MHIST mhist Classif. 2 CRC 224x224 5x 3,152 TCGA CRC-MSI tcga-crc Classif. 2 CRC 512x512 20x 51,918 ESCA esca Classif. 11 Oeso. 256x256 10x 367,229 TCGA TILS tcga-tils Classif. 2 Multi 100x100 20x 304,097 TCGA Uniform tcga-unif Classif. 32 Multi 256x256 20x 271,170 Ocelot ocelot Segm. 2 Multi 256x256 40x 10,608 PanNuke pannuke Segm. 6 Multi 256x256 40x 7,901. SegPath Epithelial segp-ep Segm. 2 Multi 256x256 40x 238,581 SegPath Lymphocytes segp-ly Segm. 2 Multi 256x256 40x 110,457"},{"location":"#available-foundation-models","title":"Available foundation models","text":"Name Short name Vision arch. Params. Training method VLM Pathology HIBOU-B hiboub ViT-B/14 86M DINOv2 x HIBOU-L hiboul ViT-L/14 307M DINOv2 x H-OPTIMUS-0 hopt0 ViT-G/14 1.1B DINOv2 x H-OPTIMUS-1 hopt1 ViT-G/14 1.1B DINOv2 x MIDNIGHT midnight ViT-G/14 1.1B DINOv2 x PHIKON phikon ViT-B/16 86M iBOT x PHIKON2 phikon2 ViT-L/16 307M DINOv2 x UNI uni ViT-L/16 307M DINOv2 x UNI2-H uni2h ViT-H/14 681M DINOv2 x VIRCHOW virchow ViT-H/14 632M DINOv2 x VIRCHOW2 virchow2 ViT-H/14 632M DINOv2 x CONCH conch ViT-B/16 86M CoCa, iBOT x x CONCH 1.5 titan ViT-L/16 307M CoCa x x KEEP keep ViT-L/16 307M CLIP x x MUSK musk V-FFN 202M CoCa, BEiT-3 x x PLIP plip ViT-B/32 86M CLIP x x QUILTNET quilt ViT-B/32 86M CLIP x x DINOv2-B dinob ViT-B/14 86M DINOv2 DINOv2-L dinol ViTL/14 307M DINOv2 ViT-B/16 vitb ViT-B/16 86M Imagenet ViT-L/16 vitl ViT-L/16 307M Imagenet CLIP-B/32 clipb ViT-B/32 86M CLIP x CLIP-L/14 clipl ViT-L/14 307M CLIP x"},{"location":"api/","title":"API","text":""},{"location":"api/#thunder.benchmark.benchmark","title":"<code>thunder.benchmark.benchmark(model, dataset, task, loading_mode='online_loading', lora=False, ckpt_save_all=False, online_wandb=False, **kwargs)</code>","text":"<p>Runs a benchmark for a pretrained model on a dataset with a task-specific approach.</p> where options are <ul> <li>dataset: bach, bcss, bracs, break_his, ccrcc, crc, esca, mhist, ocelot, pannuke, patch_camelyon, segpath_epithelial, segpath_lymphocytes, tcga_crc_msi, tcga_tils, tcga_uniform, wilds</li> <li>model: hiboub, hiboul, hoptimus0, hoptimus1, midnight, phikon, phikon2, uni, uni2h, virchow, virchow2, conch, titan, keep, musk, plip, quiltnetb32, dinov2base, dinov2large, vitbasepatch16224in21k, vitlargepatch16224in21k, clipvitbasepatch32, clipvitlargepatch14</li> <li>task: adversarial_attack_linear, alignment_scoring, image_retrieval, knn, linear_probing, pre_computing_embeddings, segmentation, simple_shot, transformation_invariance</li> <li>loading_mode: online_loading, image_pre_loading, embedding_pre_loading</li> </ul> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>str</code> <p>The name of the pretrained model to use.</p> required <code>dataset</code> <code>str</code> <p>The name of the dataset to use.</p> required <code>task</code> <code>str</code> <p>The name of the task to perform.</p> required <code>loading_mode</code> <code>str</code> <p>The type of data loading to use.</p> <code>'online_loading'</code> <code>lora</code> <code>bool</code> <p>Whether to use LoRA (Low-Rank Adaptation) for model adaptation. Default is False.</p> <code>False</code> <code>ckpt_save_all</code> <code>bool</code> <p>Whether to save all checkpoints during training. Default is False which means that only the best is saved.</p> <code>False</code> <code>online_wandb</code> <code>bool</code> <p>Whether to use online mode for Weights &amp; Biases (wandb) logging. Default is False which means offline mode.</p> <code>False</code> Source code in <code>thunder/benchmark.py</code> <pre><code>def benchmark(\n    model: str | Callable,\n    dataset: str,\n    task: str,\n    loading_mode: str = \"online_loading\",\n    lora: bool = False,\n    ckpt_save_all: bool = False,\n    online_wandb: bool = False,\n    **kwargs,\n):\n    \"\"\"\n    Runs a benchmark for a pretrained model on a dataset with a task-specific approach.\n\n    where options are:\n        - dataset: *bach*, *bcss*, *bracs*, *break_his*, *ccrcc*, *crc*, *esca*, *mhist*, *ocelot*, *pannuke*, *patch_camelyon*, *segpath_epithelial*, *segpath_lymphocytes*, *tcga_crc_msi*, *tcga_tils*, *tcga_uniform*, *wilds*\n        - model: *hiboub*, *hiboul*, *hoptimus0*, *hoptimus1*, *midnight*, *phikon*, *phikon2*, *uni*, *uni2h*, *virchow*, *virchow2*, *conch*, *titan*, *keep*, *musk*, *plip*, *quiltnetb32*, *dinov2base*, *dinov2large*, *vitbasepatch16224in21k*, *vitlargepatch16224in21k*, *clipvitbasepatch32*, *clipvitlargepatch14*\n        - task: *adversarial_attack_linear*, *alignment_scoring*, *image_retrieval*, *knn*, *linear_probing*, *pre_computing_embeddings*, *segmentation*, *simple_shot*, *transformation_invariance*\n        - loading_mode: *online_loading*, *image_pre_loading*, *embedding_pre_loading*\n\n    Args:\n        model (str): The name of the pretrained model to use.\n        dataset (str): The name of the dataset to use.\n        task (str): The name of the task to perform.\n        loading_mode (str): The type of data loading to use.\n        lora (bool): Whether to use LoRA (Low-Rank Adaptation) for model adaptation. Default is False.\n        ckpt_save_all (bool): Whether to save all checkpoints during training. Default is False which means that only the best is saved.\n        online_wandb (bool): Whether to use online mode for Weights &amp; Biases (wandb) logging. Default is False which means offline mode.\n    \"\"\"\n    from hydra import compose, initialize\n    from omegaconf import OmegaConf\n\n    from .utils.config import get_config\n\n    wandb_mode = \"online\" if online_wandb else \"offline\"\n    adaptation_type = \"lora\" if lora else \"frozen\"\n    ckpt_saving = \"save_ckpts_all_epochs\" if ckpt_save_all else \"save_best_ckpt_only\"\n    model_name = model if isinstance(model, str) else None\n\n    if model_name and model_name.startswith(\"custom:\"):\n        model = load_custom_model_from_file(model_name.split(\":\")[1])\n        model_name = None\n\n    # Get Config\n    cfg = get_config(\n        task,\n        ckpt_saving,\n        dataset,\n        model_name,\n        adaptation_type,\n        loading_mode,\n        wandb_mode,\n        **kwargs,\n    )\n\n    if not is_dataset_available(dataset):\n        from . import download_datasets\n\n        download_datasets(dataset, make_splits=True)\n\n    if model_name and not is_model_available(model_name):\n        from . import download_models\n\n        download_models(model)\n\n    if isinstance(model, str):\n        # If model is a string, cfg is already populated with the model details\n        run_benchmark(cfg)\n    else:\n        # If model is a callable, pass it directly to the benchmark function\n        run_benchmark(cfg, model)\n</code></pre>"},{"location":"api/#thunder.download_datasets","title":"<code>thunder.download_datasets(datasets, make_splits=False)</code>","text":"<p>Downloads the benchmark datasets specified in the list of dataset names.</p> <p>This function requires the <code>$THUNDER_BASE_DATA_FOLDER</code> environment variable to be set, which indicates the base directory where the datasets will be downloaded.</p> The list of all available datasets <ul> <li>bach</li> <li>bracs</li> <li>break_his</li> <li>ccrcc</li> <li>crc</li> <li>esca</li> <li>mhist</li> <li>ocelot</li> <li>pannuke</li> <li>patch_camelyon</li> <li>segpath_epithelial</li> <li>segpath_lymphocytes</li> <li>tcga_crc_msi</li> <li>tcga_tils</li> <li>tcga_uniform</li> <li>wilds</li> </ul> <p>Parameters:</p> Name Type Description Default <code>datasets</code> <code>List[str] or str</code> <p>A dataset name string or a List of dataset names to download or one of the following aliases: <code>all</code>, <code>classification</code>, <code>segmentation</code>.</p> required <code>make_splits</code> <code>bool</code> <p>Whether to generate data splits for the datasets. Defaults to False.</p> <code>False</code> Source code in <code>thunder/datasets/download.py</code> <pre><code>def download_datasets(datasets: Union[List[str], str], make_splits: bool = False):\n    \"\"\"Downloads the benchmark datasets specified in the list of dataset names.\n\n    This function requires the `$THUNDER_BASE_DATA_FOLDER` environment variable to be set,\n    which indicates the base directory where the datasets will be downloaded.\n\n    The list of all available datasets:\n        * bach\n        * bracs\n        * break_his\n        * ccrcc\n        * crc\n        * esca\n        * mhist\n        * ocelot\n        * pannuke\n        * patch_camelyon\n        * segpath_epithelial\n        * segpath_lymphocytes\n        * tcga_crc_msi\n        * tcga_tils\n        * tcga_uniform\n        * wilds\n\n    Args:\n        datasets (List[str] or str): A dataset name string or a List of dataset names to download or one of the following aliases: `all`, `classification`, `segmentation`.\n        make_splits (bool): Whether to generate data splits for the datasets. Defaults to False.\n    \"\"\"\n    if \"THUNDER_BASE_DATA_FOLDER\" not in os.environ:\n        raise EnvironmentError(\n            \"Please set base data directory of thunder using `export THUNDER_BASE_DATA_FOLDER=/base/data/directory`\"\n        )\n\n    if isinstance(datasets, str):\n        datasets = [datasets]\n\n    if len(datasets) == 1:\n        if datasets[0] == \"all\":\n            datasets = [\n                \"bach\",\n                \"bracs\",\n                \"break_his\",\n                \"ccrcc\",\n                \"crc\",\n                \"esca\",\n                \"patch_camelyon\",\n                \"tcga_crc_msi\",\n                \"tcga_tils\",\n                \"tcga_uniform\",\n                \"wilds\",\n                \"ocelot\",\n                \"pannuke\",\n                \"segpath_epithelial\",\n                \"segpath_lymphocytes\",\n                \"mhist\",\n            ]\n        elif datasets[0] == \"classification\":\n            datasets = [\n                \"bach\",\n                \"bracs\",\n                \"break_his\",\n                \"ccrcc\",\n                \"crc\",\n                \"esca\",\n                \"patch_camelyon\",\n                \"tcga_crc_msi\",\n                \"tcga_tils\",\n                \"tcga_uniform\",\n                \"wilds\",\n                \"mhist\",\n            ]\n        elif datasets[0] == \"segmentation\":\n            datasets = [\n                \"ocelot\",\n                \"pannuke\",\n                \"segpath_epithelial\",\n                \"segpath_lymphocytes\",\n            ]\n\n    for dataset in datasets:\n        download_dataset(dataset)\n        if make_splits:\n            generate_splits([dataset])\n</code></pre>"},{"location":"api/#thunder.download_models","title":"<code>thunder.download_models(models)</code>","text":"<p>Download model checkpoints from Hugging Face.</p> The list of all available models <ul> <li>uni</li> <li>uni2h</li> <li>virchow</li> <li>virchow2</li> <li>hoptimus0</li> <li>hoptimus1</li> <li>conch</li> <li>titan</li> <li>phikon</li> <li>phikon2</li> <li>hiboub</li> <li>hiboul</li> <li>midnight</li> <li>keep</li> <li>quiltb32</li> <li>plip</li> <li>musk</li> <li>dinov2base</li> <li>dinov2large</li> <li>vitbasepatch16224in21k</li> <li>vitlargepatch16224in21k</li> <li>clipvitbasepatch32</li> <li>clipvitlargepatch14</li> </ul> <p>Parameters:</p> Name Type Description Default <code>models</code> <code>List[str] or str</code> <p>a list of model names or single a model name str.</p> required Source code in <code>thunder/models/download.py</code> <pre><code>def download_models(models: Union[List[str], str]) -&gt; None:\n    \"\"\"Download model checkpoints from Hugging Face.\n\n    The list of all available models:\n        * uni\n        * uni2h\n        * virchow\n        * virchow2\n        * hoptimus0\n        * hoptimus1\n        * conch\n        * titan\n        * phikon\n        * phikon2\n        * hiboub\n        * hiboul\n        * midnight\n        * keep\n        * quiltb32\n        * plip\n        * musk\n        * dinov2base\n        * dinov2large\n        * vitbasepatch16224in21k\n        * vitlargepatch16224in21k\n        * clipvitbasepatch32\n        * clipvitlargepatch14\n\n    Args:\n        models (List[str] or str): a list of model names or single a model name str.\n    \"\"\"\n    if isinstance(models, str):\n        models = [models]\n\n    for model in models:\n        if model not in TAGS_FILENAMES:\n            raise ValueError(f\"Model {model} is not available.\")\n        download_model(model)\n</code></pre>"},{"location":"api/#thunder.generate_splits","title":"<code>thunder.generate_splits(datasets)</code>","text":"<p>Generates the data splits for all datasets in input list.</p> <p>This function requires the <code>$THUNDER_BASE_DATA_FOLDER</code> environment variable to be set, which indicates the base directory where the datasets will be downloaded.</p> <p>Parameters:</p> Name Type Description Default <code>datasets</code> <code>List[str]</code> <p>List of dataset names to generate splits for or one of the following aliases: <code>all</code>, <code>classification</code>, <code>segmentation</code>.</p> required Source code in <code>thunder/datasets/data_splits.py</code> <pre><code>def generate_splits(datasets: Union[List[str], str]) -&gt; None:\n    \"\"\"Generates the data splits for all datasets in input list.\n\n    This function requires the `$THUNDER_BASE_DATA_FOLDER` environment variable to be set,\n    which indicates the base directory where the datasets will be downloaded.\n\n    Args:\n        datasets (List[str]): List of dataset names to generate splits for or one of the following aliases: `all`, `classification`, `segmentation`.\n    \"\"\"\n\n    if isinstance(datasets, str):\n        datasets = [datasets]\n\n    if len(datasets) == 1:\n        if datasets[0] == \"all\":\n            datasets = [\n                \"bach\",\n                \"bracs\",\n                \"break_his\",\n                \"ccrcc\",\n                \"crc\",\n                \"esca\",\n                \"patch_camelyon\",\n                \"tcga_crc_msi\",\n                \"tcga_tils\",\n                \"tcga_uniform\",\n                \"wilds\",\n                \"ocelot\",\n                \"pannuke\",\n                \"segpath_epithelial\",\n                \"segpath_lymphocytes\",\n                \"mhist\",\n            ]\n        elif datasets[0] == \"classification\":\n            datasets = [\n                \"bach\",\n                \"bracs\",\n                \"break_his\",\n                \"ccrcc\",\n                \"crc\",\n                \"esca\",\n                \"patch_camelyon\",\n                \"tcga_crc_msi\",\n                \"tcga_tils\",\n                \"tcga_uniform\",\n                \"wilds\",\n                \"mhist\",\n            ]\n        elif datasets[0] == \"segmentation\":\n            datasets = [\n                \"ocelot\",\n                \"pannuke\",\n                \"segpath_epithelial\",\n                \"segpath_lymphocytes\",\n            ]\n\n    base_folder = os.path.join(os.environ[\"THUNDER_BASE_DATA_FOLDER\"], \"datasets\")\n    data_splits_folder = os.path.join(base_folder, \"data_splits\")\n    os.makedirs(data_splits_folder, exist_ok=True)\n\n    # Generating data splits\n    for dataset_name in datasets:\n        generate_splits_for_dataset(dataset_name)\n</code></pre>"},{"location":"api/#thunder.models.PretrainedModel","title":"<code>thunder.models.PretrainedModel</code>","text":"<p>               Bases: <code>Module</code>, <code>ABC</code></p> <p>Abstract class to be inherited by custom pretrained models.</p> Source code in <code>thunder/models/pretrained_models.py</code> <pre><code>class PretrainedModel(torch.nn.Module, ABC):\n    \"\"\"Abstract class to be inherited by custom pretrained models.\"\"\"\n\n    @abstractmethod\n    def get_transform(self):\n        \"\"\"Returns the transform function to be applied to the input images.\"\"\"\n        pass\n\n    @abstractmethod\n    def get_linear_probing_embeddings(self, x):\n        \"\"\"Returns the embeddings for linear probing.\"\"\"\n        pass\n\n    @abstractmethod\n    def get_segmentation_embeddings(self, x):\n        \"\"\"Returns the pixel dense embeddings for segmentation.\"\"\"\n        pass\n\n    def get_embeddings(self, x, model, task_type):\n        if task_type == \"linear_probing\":\n            return self.get_linear_probing_embeddings(x)\n        elif task_type == \"segmentation\":\n            return self.get_segmentation_embeddings(x)\n        else:\n            raise ValueError(f\"Invalid task type {task_type}\")\n</code></pre>"},{"location":"api/#thunder.models.PretrainedModel.get_linear_probing_embeddings","title":"<code>get_linear_probing_embeddings(x)</code>  <code>abstractmethod</code>","text":"<p>Returns the embeddings for linear probing.</p> Source code in <code>thunder/models/pretrained_models.py</code> <pre><code>@abstractmethod\ndef get_linear_probing_embeddings(self, x):\n    \"\"\"Returns the embeddings for linear probing.\"\"\"\n    pass\n</code></pre>"},{"location":"api/#thunder.models.PretrainedModel.get_segmentation_embeddings","title":"<code>get_segmentation_embeddings(x)</code>  <code>abstractmethod</code>","text":"<p>Returns the pixel dense embeddings for segmentation.</p> Source code in <code>thunder/models/pretrained_models.py</code> <pre><code>@abstractmethod\ndef get_segmentation_embeddings(self, x):\n    \"\"\"Returns the pixel dense embeddings for segmentation.\"\"\"\n    pass\n</code></pre>"},{"location":"api/#thunder.models.PretrainedModel.get_transform","title":"<code>get_transform()</code>  <code>abstractmethod</code>","text":"<p>Returns the transform function to be applied to the input images.</p> Source code in <code>thunder/models/pretrained_models.py</code> <pre><code>@abstractmethod\ndef get_transform(self):\n    \"\"\"Returns the transform function to be applied to the input images.\"\"\"\n    pass\n</code></pre>"},{"location":"custom_config/","title":"Overriding Configurations","text":""},{"location":"custom_config/#overriding-config-parameters","title":"Overriding config parameters","text":"<p>Default parameters are used for various aspects of the benchmark, e.g., the batch sizes, learning rates. These default parameters can be overriden using the following syntaxes for both CLI and API uses.</p> <pre><code>thunder benchmark hiboub bach knn --task.pre_comp_emb_batch_size 123 \\\n                                  --task.k_vals \"[1, 2, 3]\"\n</code></pre> <pre><code>import thunder\nthunder.benchmark('hiboub',\n                  'bach',\n                  'knn',\n                  **{'task.pre_comp_emb_batch_size': 123, 'task.k_vals': [1, 2, 3]})\n</code></pre>"},{"location":"custom_config/#overridable-parameters","title":"Overridable parameters","text":"<p>Here is a non exhaustive list of the parameters that you may want to override per task, as well as the type and a small description.</p>"},{"location":"custom_config/#frozen-linear-probing","title":"Frozen linear probing","text":"Name Type Description adaptation.batch_size int Batch size used for training. adaptation.num_workers int Number of workers for the data loader. adaptation.lr list[int] List of learning rates used for the grid search. adaptation.weight_decay list[int] List of weight decays used for the grid search. adaptation.epochs int Number of training epochs."},{"location":"custom_config/#lora-linear-probing","title":"LoRA linear probing","text":"Name Type Description adaptation.lora_rank int Rank for the LoRA adapter. adaptation.lora_alpha int Alpha parameter for LoRA. adaptation.batch_size int Batch size used for training. adaptation.num_workers int Number of workers for the data loader. adaptation.lr list[int] List of learning rates used for the grid search. adaptation.weight_decay list[int] List of weight decays used for the grid search. adaptation.epochs int Number of training epochs."},{"location":"custom_config/#adversarial-attack","title":"Adversarial attack","text":"Name Type Description task.pre_comp_emb_batch_size int Batch size for precomputing the embeddings. task.attack_batch_size int Batch size for the attacks. task.nb_attack_images int Number of images to use. task.attack.eps float Radius of the norm ball. task.attack.alpha float Step size per PGD iteration. task.attack.n_steps int Number of PGD iterations."},{"location":"custom_config/#alignment-scoring","title":"Alignment scoring","text":"Name Type Description task.pre_comp_emb_batch_size int Batch size for precomputing the embeddings."},{"location":"custom_config/#image-retrieval","title":"Image retrieval","text":"Name Type Description task.pre_comp_emb_batch_size int Batch size for precomputing the embeddings. task.k_vals list[int] Values of k to use."},{"location":"custom_config/#k-nn","title":"K-nn","text":"Name Type Description task.pre_comp_emb_batch_size int Batch size for precomputing the embeddings. task.k_vals list[int] Values of k to use."},{"location":"custom_config/#precomputing-embeddings","title":"Precomputing embeddings","text":"Name Type Description task.pre_comp_emb_batch_size int Batch size for precomputing the embeddings."},{"location":"custom_config/#simple-shot","title":"Simple shot","text":"Name Type Description task.pre_comp_emb_batch_size int Batch size for precomputing the embeddings."},{"location":"custom_config/#transformation-invariance","title":"Transformation invariance","text":"Name Type Description task.pre_comp_emb_batch_size int Batch size for precomputing the embeddings. task.nb_images int Number of images to use."},{"location":"custom_model/","title":"Benchmark a Custom Model","text":"<p>You can use any custom model to run the benchmark by inheriting from the <code>thunder.models.PretrainedModel</code> class.</p> <p>Note</p> <p>A few examples of such files described bellow can be found in the <code>examples</code> folder of the repository.</p> <p>To do so you will need to prepare a <code>.py</code> with a class definition of your model that inherits from <code>thunder.models.PretrainedModel</code> and overrides the following methods:</p> <ul> <li><code>get_transform</code>: This method should return a transform function that will be used to preprocess the input data. The transform function should take a single argument, which is the input data, and return the transformed data.</li> <li><code>get_linear_probing_embeddings</code>: This method should return the embeddings for the linear probing task. It should take a single argument, which is the input data, and return the embeddings (bs, emb_size).</li> <li><code>get_segmentation_embeddings</code>: This method should return the embeddings for the segmentation task. It should take a single argument, which is the input data, and return the embeddings (bs, tokens, emb_size).</li> </ul> <p>Additionally two properties should be available in the class: </p> <ul> <li><code>name</code>: This property should return the name of the model.  </li> <li><code>emb_dim</code>: This property should return the embedding dimension of the model.</li> </ul> <p>Here is an example of such a file:</p> <pre><code># my_model.py\nfrom thunder.models import PretrainedModel\n\nclass DINOv2Features(PretrainedModel):\n    def __init__(self):\n        super().__init__()\n\n        import torch\n        from torchvision import transforms\n\n        self.dinov2 = torch.hub.load(\"facebookresearch/dinov2\", \"dinov2_vits14\")\n        self.t = transforms.Compose(\n            [\n                transforms.ToTensor(),\n                transforms.Resize((224, 224)),\n            ]\n        )\n        self.name = \"dinov2_vits14\"\n        self.emb_dim = 384\n\n    def forward(self, x):\n        feats = self.dinov2.forward_features(x)\n        return feats\n\n    def get_transform(self):\n        return self.t\n\n    def get_linear_probing_embeddings(self, x):\n        x = self.dinov2.forward_features(x)\n        return x[\"x_norm_clstoken\"]\n\n    def get_segmentation_embeddings(self, x):\n        x = self.dinov2.forward_features(x)\n        return x['x_norm_patchtokens']\n</code></pre> <p>With this file ready, you can run any benchmark task using the following command:</p> <pre><code>thunder benchmark custom:my_model.py db_name task_name\n</code></pre> <p>or through the API:</p> <pre><code>from thunder import benchmark\nfrom my_model import DINOv2Features\n\nif __name__ == \"__main__\":\n    model = DINOv2Features()\n    benchmark(model, dataset=\"ccrcc\", task=\"linear_probing\")\n</code></pre>"},{"location":"getting_started/","title":"Getting Started","text":""},{"location":"getting_started/#installation","title":"Installation","text":"<p>In order to use the package, you need to install it first. You can do this by running the following command in your terminal:</p> <pre><code>pip install thundr\n</code></pre> <p>The package is storing all the datasets, models and results under a folder that you will need to define through the environment variable <code>THUNDER_BASE_DATA_FOLDER</code>. You can do this by running the following command in your terminal: <pre><code>export THUNDER_BASE_DATA_FOLDER=/path/to/thunder_base_data_folder\n</code></pre></p> <p>Important</p> <p>Without this environment variable, the package will not work. The folder should be empty and the package will create the necessary subfolders.</p>"},{"location":"getting_started/#cli-usage","title":"CLI Usage","text":"<p>You can run the following command to see all available options, <pre><code>&gt; thunder --help\n Usage: thunder [OPTIONS] COMMAND [ARGS]...\n</code></pre></p> <p>The available commands are: - <code>benchmark</code>: Benchmarks the models on the datasets for a task. - <code>download-datasets</code>: Downloads datasets. - <code>download-models</code>: Downloads models. - <code>generate-data-splits</code>: Generate data splits for the downloaded datasets. - <code>results-summary</code>: Compiles a summary csv file of the results.</p> <p>To benchmark the models, you can run the following command, <pre><code>&gt; thunder benchmark --help\nUsage: thunder benchmark [OPTIONS] MODEL DATASET TASK\n&gt; thunder benchmark phikon ccrcc knn\n</code></pre></p> <p>In case you want to download a datasets, you can run the following command, <pre><code>&gt; thunder download-datasets ccrcc patch_camelyon bach\n&gt; thunder download-datasets classification\n&gt; thunder download-datasets all --make_splits # Generates splits after downloading\n</code></pre></p> <p>To download the models, you can run the following command, <pre><code>&gt; thunder download-models phikon keep\n&gt; thunder download-models dinov2base\n</code></pre></p> <p>To generate splits for the downloaded, you can run the following command, <pre><code>&gt; thunder generate-data-splits ccrcc patch_camelyon bach\n&gt; thunder generate-data-splits classification\n&gt; thunder generate-data-splits all\n</code></pre></p>"},{"location":"getting_started/#api-usage","title":"API Usage","text":"<p>You can also use the package as a library. For example, you can run the following code to download datasets, <pre><code>from thunder import download_datasets, download_models, generate_splits, benchmark\n\n# Download datasets\ndownload_datasets([\"ccrcc\", \"patch_camelyon\", \"bach\"])\ndownload_datasets([\"all\"])\ndownload_datasets([\"classification\"])\n\n# Download models\ndownload_models([\"phikon\", \"dinov2base\"])\n\n# Generate data splits\ngenerate_splits([\"all\"])\n\n# Benchmark\nbenchmark(model=\"phikon\", dataset=\"ccrcc\", task=\"knn\")\n</code></pre></p>"}]}